{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analyze customer sentiment from twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import scipy \n",
    "import scipy.stats as stats\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image # displaying images files in jupyter\n",
    "from IPython.display import IFrame # displaying pdf file in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>Lets Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline negativereason_gold  \\\n",
       "0                        NaN  Virgin America                 NaN   \n",
       "1                     0.0000  Virgin America                 NaN   \n",
       "2                        NaN  Virgin America                 NaN   \n",
       "3                     0.7033  Virgin America                 NaN   \n",
       "4                     1.0000  Virgin America                 NaN   \n",
       "\n",
       "                                                text tweet_location  \n",
       "0                @VirginAmerica What @dhepburn said.            NaN  \n",
       "1  @VirginAmerica plus you've added commercials t...            NaN  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...      Lets Play  \n",
       "3  @VirginAmerica it's really aggressive to blast...            NaN  \n",
       "4  @VirginAmerica and it's a really big bad thing...            NaN  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input and clean up data by removing columns not useful for analysis\n",
    "tweets = pd.read_csv('Tweets.csv')\n",
    "del tweets['tweet_id']\n",
    "del tweets['retweet_count']\n",
    "del tweets['tweet_coord']\n",
    "del tweets['name']\n",
    "del tweets['airline_sentiment_gold']\n",
    "del tweets['tweet_created']\n",
    "del tweets['user_timezone']\n",
    "tweets.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airlines:  ['Virgin America' 'United' 'Southwest' 'Delta' 'US Airways' 'American']\n",
      " \n",
      "Sentiment:  ['neutral' 'positive' 'negative']\n",
      " \n",
      "Negative comments:  ['Bad Flight' \"Can't Tell\" 'Late Flight' 'Customer Service Issue'\n",
      " 'Flight Booking Problems' 'Lost Luggage' 'Flight Attendant Complaints'\n",
      " 'Cancelled Flight' 'Damaged Luggage' 'longlines']\n",
      " \n",
      "Locations:  ['Lets Play' 'San Francisco CA' 'Los Angeles' ..., 'Columbus, OH, USA'\n",
      " 'Milwaukee County, Wisconsin' 'Nigeria,lagos']\n"
     ]
    }
   ],
   "source": [
    "# scanning data\n",
    "print (\"Airlines: \", tweets['airline'].dropna().unique())\n",
    "print (\" \")\n",
    "print (\"Sentiment: \", tweets['airline_sentiment'].dropna().unique())\n",
    "print (\" \")\n",
    "print (\"Negative comments: \", tweets['negativereason'].dropna().unique())\n",
    "print (\" \")\n",
    "print (\"Locations: \", tweets['tweet_location'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to clean up Twitter text\n",
    "def clean_tweet(str):\n",
    "\n",
    "    str = str.lower() \n",
    "    tokens = nltk.word_tokenize(str)                            # tokenize\n",
    "    tokens = [i for i in tokens if i not in string.punctuation] # remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [i for i in tokens if i not in stop_words]  # remove stop words\n",
    "    tokens = [i for i in tokens if   not i.isdigit()]    # remove numbers\n",
    "    tokens = [i for i in tokens if i.isalnum()]          # remove alpha numeric characters\n",
    "\n",
    "    tokens = list(set(tokens)) # Remove duplicates.\n",
    "    #print(\"Length: \", len(tokens))\n",
    "    \n",
    "    clean_text = ' '.join(token for token in tokens)\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhepburn said virginamerica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plus tacky added experience commercials virgin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>mean need another today trip take must virgina...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blast amp guests recourse obnoxious faces real...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>big really bad virginamerica thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0           neutral                        1.0000            NaN   \n",
       "1          positive                        0.3486            NaN   \n",
       "2           neutral                        0.6837            NaN   \n",
       "3          negative                        1.0000     Bad Flight   \n",
       "4          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline negativereason_gold  \\\n",
       "0                        NaN  Virgin America                 NaN   \n",
       "1                     0.0000  Virgin America                 NaN   \n",
       "2                        NaN  Virgin America                 NaN   \n",
       "3                     0.7033  Virgin America                 NaN   \n",
       "4                     1.0000  Virgin America                 NaN   \n",
       "\n",
       "                                                text tweet_location  \\\n",
       "0                @VirginAmerica What @dhepburn said.            NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...            NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...      Lets Play   \n",
       "3  @VirginAmerica it's really aggressive to blast...            NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...            NaN   \n",
       "\n",
       "                                         clean_tweet  sentiment  \n",
       "0                        dhepburn said virginamerica          0  \n",
       "1  plus tacky added experience commercials virgin...          1  \n",
       "2  mean need another today trip take must virgina...          0  \n",
       "3  blast amp guests recourse obnoxious faces real...          0  \n",
       "4                 big really bad virginamerica thing          0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add clean tweets field.\n",
    "#print (tweets_train['text'][0])\n",
    "#print (clean_tweet(tweets_train['text'][0]))\n",
    "tweets['clean_tweet']= tweets['text'].apply(lambda s: clean_tweet(s))\n",
    "tweets['sentiment'] =  tweets['airline_sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (13176, 10)\n",
      "Test:  (1464, 10)\n"
     ]
    }
   ],
   "source": [
    "# Predictive Modeling, predicted_sentiment based on twitter text.\n",
    "\n",
    "tweets_train, tweets_test = train_test_split(tweets, test_size=0.10, random_state=42)\n",
    "print (\"Training: \", tweets_train.shape)\n",
    "print (\"Test: \", tweets_test.shape)\n",
    "\n",
    "# train and test clean tweets.\n",
    "train_clean_tweet=[]\n",
    "for t in tweets_train['clean_tweet']:\n",
    "    train_clean_tweet.append(t)\n",
    "test_clean_tweet=[]\n",
    "for t in tweets_test['clean_tweet']:\n",
    "    test_clean_tweet.append(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict Sentiment of the tweet (Positive (1) or Negative/Neutral) \n",
    "\n",
    "# Reference: http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# Build training and test features matrix from relevant clean tweet text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(analyzer = \"word\")\n",
    "train_features = v.fit_transform(train_clean_tweet)\n",
    "test_features  = v.transform(test_clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Training data correct classification:  0.83872191864\n",
      " \n",
      "Cross validation score:\n",
      "[ 0.83673469  0.83617747  0.83617747  0.8390411   0.8390411 ]\n",
      "Accuracy: 0.84 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classifier\n",
    "\n",
    "clf = svm.SVC(kernel=\"rbf\", C=0.025, probability=True)\n",
    "clf.fit(train_features,tweets_train['sentiment'])\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(\"Training data correct classification: \", clf.score(train_features,tweets_train['sentiment']))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Cross validation score:\")\n",
    "scores = cross_val_score(clf, test_features,tweets_test['sentiment'], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Classifier:\n",
      "Training data correct classification:  0.996508803886\n",
      " \n",
      "Cross validation score:\n",
      "[ 0.83333333  0.81569966  0.79863481  0.80136986  0.81164384]\n",
      "Accuracy: 0.81 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(train_features,tweets_train['sentiment'])\n",
    "\n",
    "print(\"Tree Classifier:\")\n",
    "print(\"Training data correct classification: \", clf.score(train_features,tweets_train['sentiment']))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Cross validation score:\")\n",
    "scores = cross_val_score(clf, test_features,tweets_test['sentiment'], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors:\n",
      "Training data correct classification:  0.908166363084\n",
      " \n",
      "Cross validation score:\n",
      "[ 0.78231293  0.75767918  0.76109215  0.79109589  0.80479452]\n",
      "Accuracy: 0.78 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(train_features,tweets_train['sentiment'])\n",
    "\n",
    "print(\"K Neighbors:\")\n",
    "print(\"Training data correct classification: \", clf.score(train_features,tweets_train['sentiment']))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Cross validation score:\")\n",
    "scores = cross_val_score(clf, test_features,tweets_test['sentiment'], cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std())) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "(1) Dataset: https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "\n",
    "(2) www.nltk.org\n",
    "\n",
    "(3) http://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
