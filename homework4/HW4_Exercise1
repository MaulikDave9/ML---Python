from sklearn import svm # read more at: scikit-learn.org
from sklearn.model_selection import cross_val_score
from sklearn.svm import LinearSVC
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pydot_ng as pydot # visualization of trees (among many others)
%matplotlib inline

df = pd.read_csv('Auto.csv')
mpg_med = df.mpg.median()
df['abovemedian'] = np.where(df['mpg'] > mpg_med, 1, 0)
C_range = [0.1, 1, 5, 10]
fig, axes = plt.subplots(1,len(C_range), figsize=(10,3))
l=5 

for i in range(len(C_range)):
    clf = svm.SVC(kernel='linear',C=C_range[i])
    clf.fit(df[['mpg','cylinders']], df['abovemedian'])

    beta1,beta2 = clf.coef_[0]
    beta0 = clf.intercept_[0]
    M = 1/np.sqrt(beta1**2+beta2**2) # margin
    training_error=sum(clf.predict(df[['mpg','cylinders']])!=df['abovemedian'])

    axes[i].scatter(df['mpg'], df['cylinders'], c=df['abovemedian'], cmap=plt.cm.Paired)
    X1_range = [0, 50]
    X2_hyperplane = list(map(lambda x1:(-beta0-beta1*x1)/beta2, X1_range))
    X2_margin1 = list(map(lambda x1:(-beta0-1-beta1*x1)/beta2, X1_range))
    X2_margin2 = list(map(lambda x1:(-beta0+1-beta1*x1)/beta2, X1_range))

    axes[i].plot(X1_range,X2_hyperplane,'-k')
    axes[i].plot(X1_range,X2_margin1,'--k')
    axes[i].plot(X1_range,X2_margin2,'--k')
    axes[i].scatter(clf.support_vectors_[:,0], clf.support_vectors_[:,1], s=80, facecolors='none')
    axes[i].set_xlabel('mpg')
    axes[i].set_ylabel('cylinders')
    axes[i].set_xlim([0, 50])
    axes[i].set_ylim([0,10])    
    axes[i].set_title("C=%.2f, M=%.2f, \nTraining errors=%d"%(C_range[i],M,training_error))
        
fig.tight_layout()

#  cross validation
X=df[['mpg','cylinders']]
Y=df['abovemedian']
for C in C_range:
    print("C: "+ str(C))
    clf = svm.SVC(kernel='linear',C=C)  
    scores = cross_val_score(clf, X, Y, cv=5)
    print(scores)
    print("C=%.2f Accuracy: %0.2f (+/- %0.2f)" % (0.1,scores.mean(), scores.std()))  
    print("\n")